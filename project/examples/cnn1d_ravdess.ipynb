{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of 1D CNN on RAVDESS data (numpy implementation)\n",
    "Wei Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAVDESS Emotional speech audio\n",
    "## https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
    "## Speech audio-only files (16bit, 48kHz .wav) from the RAVDESS.\n",
    "##\n",
    "## This portion of the RAVDESS contains 1440 files: 60 trials per actor x 24 actors = 1440.\n",
    "## The RAVDESS contains 24 professional actors (12 female, 12 male),\n",
    "## vocalizing two lexically-matched statements in a neutral North American accent.\n",
    "## Speech emotions includes calm, happy, sad, angry, fearful, surprise, and disgust expressions.\n",
    "## Each expression is produced at two levels of emotional intensity (normal, strong), with an additional neutral expression.\n",
    "\n",
    "# The filename consists of a 7-part numerical identifier (e.g., 03-01-06-01-02-01-12.wav). These identifiers define the stimulus characteristics:\n",
    "\n",
    "# Filename identifiers:\n",
    "# Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "# Vocal channel (01 = speech, 02 = song).\n",
    "# Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "# Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "# Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "# Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "# Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "# Filename example: 03-01-06-01-02-01-12.wav\n",
    "\n",
    "# Emotions in the RAVDESS dataset\n",
    "# emotions = {\n",
    "#     \"01\": \"neutral\",\n",
    "#     \"02\": \"calm\",\n",
    "#     \"03\": \"happy\",\n",
    "#     \"04\": \"sad\",\n",
    "#     \"05\": \"angry\",\n",
    "#     \"06\": \"fearful\",\n",
    "#     \"07\": \"disgust\",\n",
    "#     \"08\": \"surprised\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import soundfile\n",
    "import librosa\n",
    "\n",
    "# SoundFile is not available for a conda install.\n",
    "# pip install SoundFile\n",
    "\n",
    "# If error occurs: \".../envs/py38torch/lib/libffi.7.dylib' (no such file)\"\n",
    "# try the following:\n",
    "# cd /Users/wli169/miniconda3/envs/py38torch/lib/\n",
    "# ln -s libffi.6.dylib libffi.7.dylib\n",
    "# This command creates a symbolic link named libffi.7.dylib\n",
    "# that points to the file libffi.6.dylib.\n",
    "\n",
    "sys.path\n",
    "# If running the .py script, uncomment the next line\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "# add parent directory: adds the parent directory of the module requiring it (__file__)\n",
    "# to the beginning of the module search path.\n",
    "\n",
    "# change the working directory to the parent folder\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import get_data_utils\n",
    "from utils import data_processor\n",
    "from models.cnn import *\n",
    "from nn.modules.loss import *\n",
    "from nn.modules.activation import *\n",
    "from nn.modules.linear import *\n",
    "from nn.modules.dropout import *\n",
    "from nn.modules.initializer import *\n",
    "from optim.sgd import *\n",
    "from optim.adam import *\n",
    "from evaluation.multiclass_eval import *\n",
    "\n",
    "import random\n",
    "\n",
    "random_seed = 123\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Author: Wei Li\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.17\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "numpy    : 1.21.5\n",
      "torch    : 1.12.1\n",
      "soundfile: 0.12.1\n",
      "librosa  : 0.10.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -a \"Wei Li\" -u -t -d -v -p numpy,torch,soundfile,librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 310)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset of emotions under consideration\n",
    "# emotions_labels = [\"calm\", \"happy\", \"fearful\", \"disgust\"]\n",
    "emotions_labels = [\n",
    "    \"neutral\",\n",
    "    \"calm\",\n",
    "    \"happy\",\n",
    "    \"sad\",\n",
    "    \"angry\",\n",
    "    \"fearful\",\n",
    "    \"disgust\",\n",
    "    \"surprised\",\n",
    "]\n",
    "\n",
    "###############################################\n",
    "#### -----  check on one example -------- ####\n",
    "###############################################\n",
    "\n",
    "example, sr = librosa.load(\n",
    "    \"/Users/wli169/Documents/Work/datasets/RAVDESS-speech/Actor_01/03-01-01-01-01-01-01.wav\",\n",
    "    sr=48000,  # default resampling rate sr=22050\n",
    ")\n",
    "# Note: an alternative way to load is to use soundfile.SoundFile()\n",
    "# however,there is some file cannot be properly loaded,\n",
    "# e.g. /Actor_20/03-01-06-01-01-02-20.wav\n",
    "# as the duration got truncated\n",
    "\n",
    "librosa.get_duration(y=example, sr=48000)\n",
    "\n",
    "type(example), example.shape\n",
    "# np.ndarray shape: (158558,) where 48000*1*3.3 secs\n",
    "# mono (1 channel)\n",
    "\n",
    "librosa.feature.mfcc(\n",
    "    y=example, sr=48000, n_mfcc=40\n",
    ").shape  # (n_mfcc, t=num_frames)=(40, 310), default n_mfcc=40\n",
    "\n",
    "stft = librosa.stft(example)\n",
    "librosa.feature.chroma_stft(S=stft, sr=48000, n_chroma=12).shape  #  default n_chroma=12\n",
    "\n",
    "librosa.feature.melspectrogram(\n",
    "    y=example, sr=48000, n_mels=128\n",
    ").shape  # default n_mels=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "#### -----  load data -------- ####\n",
    "### We set chroma=True, mel=True\n",
    "######################################\n",
    "\n",
    "# This function extracts audio features from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    # Open the sound file using 'librosa' library and read samples into variable 'X'\n",
    "    X, sample_rate = librosa.load(file_name, sr=48000, dtype=\"float32\")\n",
    "    # If chroma is true, calculate short-time Fourier transform of X\n",
    "    if chroma:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Create an empty numpy array called 'result'\n",
    "    result = np.array([])\n",
    "    # If mfcc is true, calculate mean across all frames of 40 MFCC coefficients and store them in 'result'\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(\n",
    "            librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0\n",
    "        )  # mfccs: shape (n_mfcc, )\n",
    "        result = np.hstack((result, mfccs))\n",
    "    # If chroma is true, calculate mean across all frames of chroma feature and store it in 'result'\n",
    "    if chroma:\n",
    "        chroma = np.mean(\n",
    "            librosa.feature.chroma_stft(S=stft, sr=sample_rate, n_chroma=12).T,\n",
    "            axis=0,\n",
    "        )\n",
    "        result = np.hstack((result, chroma))\n",
    "    # If mel is true, calculate mean across all frames of mel spectrogram and store it in 'result'\n",
    "    if mel:\n",
    "        mel = np.mean(\n",
    "            librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128).T,\n",
    "            axis=0,\n",
    "        )\n",
    "        result = np.hstack((result, mel))\n",
    "    # Return the resulting numpy array containing extracted features\n",
    "    return result\n",
    "\n",
    "\n",
    "example_feature = extract_feature(\n",
    "    \"/Users/wli169/Documents/Work/datasets/RAVDESS-speech/Actor_01/03-01-01-01-01-01-01.wav\",\n",
    "    mfcc=True,\n",
    "    chroma=True,\n",
    "    mel=True,\n",
    ")\n",
    "# shape (180, ) , 40 mfccs + 12 chroma + 128 mels = 180 features\n",
    "example_feature.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1152, 180), (288, 180))\n",
      "((1152,), (288,))\n"
     ]
    }
   ],
   "source": [
    "# load np_ravdess numpy data\n",
    "x_dat, y_dat = get_data_utils.get_np_ravdess(emotions_labels, extract_feature, chroma_T=True, mel_T=True)\n",
    "x_dat.shape, y_dat.shape\n",
    "# total sample:  ((1440, 180), (1440,))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_dat, y_dat, test_size=0.2, random_state=2023, stratify=y_dat\n",
    ")\n",
    "x_train.shape, x_test.shape\n",
    "# since we have a small dataset, we just use validation data as test data\n",
    "# stratify=y_dat: each category is roughly equally represented in training and test data\n",
    "\n",
    "# Get the shape of the training and testing datasets\n",
    "print((x_train.shape, x_test.shape))\n",
    "print((y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.22%\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "### ----- toy MLP from scikilearn ----- ###\n",
    "###########################################\n",
    "\n",
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model = MLPClassifier(\n",
    "    alpha=0.01,\n",
    "    batch_size=128,\n",
    "    epsilon=1e-08,\n",
    "    hidden_layer_sizes=(256, 128),\n",
    "    learning_rate=\"adaptive\",\n",
    "    max_iter=1000,\n",
    "    random_state=2023,\n",
    ")\n",
    "\n",
    "# DataFlair - Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# DataFlair - Predict for the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# DataFlair - Calculate the accuracy of our model\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "# DataFlair - Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "# Accuracy: 47.22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "The model architecture:\n",
      "layer0:\n",
      "\tsublayer0: <nn.modules.conv.Conv1D object at 0x28f219730>\n",
      "\tsublayer1: <nn.modules.activation.Tanh object at 0x11011f1c0>\n",
      "layer1:\n",
      "\tsublayer0: <nn.modules.conv.Pool1D object at 0x28f219520>\n",
      "layer2:\n",
      "\tsublayer0: <nn.modules.conv.Conv1D object at 0x28f223e20>\n",
      "\tsublayer1: <nn.modules.activation.ReLU object at 0x28d5406a0>\n",
      "layer3:\n",
      "\tsublayer0: <nn.modules.conv.Pool1D object at 0x28f223f10>\n",
      "layer4:\n",
      "\tsublayer0: <nn.modules.conv.Conv1D object at 0x28f223a60>\n",
      "\tsublayer1: <nn.modules.activation.Sigmoid object at 0x28f219190>\n",
      "layer5:\n",
      "\tsublayer0: <nn.modules.conv.Pool1D object at 0x28f223c10>\n",
      "layer6:\n",
      "\tsublayer0: <nn.modules.conv.Flatten1D object at 0x28f219640>\n",
      "layer7:\n",
      "\tsublayer0: <nn.modules.linear.Linear object at 0x28f223910>\n",
      "\n",
      "---------------------------------\n",
      "layers with learnable parameters:\n",
      "layer0 \n",
      " (0)conv1d\n",
      "(8, 1, 10)\n",
      "(8, 1)\n",
      "\n",
      "layer2 \n",
      " (0)conv1d\n",
      "(8, 8, 10)\n",
      "(8, 1)\n",
      "\n",
      "layer4 \n",
      " (0)conv1d\n",
      "(4, 8, 4)\n",
      "(4, 1)\n",
      "\n",
      "layer7 \n",
      " (0)linear\n",
      "(8, 32)\n",
      "(8, 1)\n",
      "\n",
      "layer0 \n",
      " (0)conv1d\n",
      "(8, 1, 10)\n",
      "(8, 1)\n",
      "\n",
      "layer2 \n",
      " (0)conv1d\n",
      "(8, 8, 10)\n",
      "(8, 1)\n",
      "\n",
      "layer4 \n",
      " (0)conv1d\n",
      "(4, 8, 4)\n",
      "(4, 1)\n",
      "\n",
      "layer7 \n",
      " (0)linear\n",
      "(8, 32)\n",
      "(8, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "######## ----- CONV1D ----- ##########\n",
    "######################################\n",
    "\n",
    "# process data targets\n",
    "y_train = data_processor.label_to_num(y_train, emotions_labels)\n",
    "y_test = data_processor.label_to_num(y_test, emotions_labels)\n",
    "\n",
    "np.bincount(y_train), np.bincount(y_test)\n",
    "# each categori is roughly equally represented in training and test data\n",
    "\n",
    "y_train = data_processor.to_onehot(y_train.reshape(-1, 1), len(emotions_labels))\n",
    "y_test = data_processor.to_onehot(y_test.reshape(-1, 1), len(emotions_labels))\n",
    "\n",
    "# normalize data input\n",
    "dat_norm = data_processor.input_normalizer()\n",
    "x_train = dat_norm.fit_transform(x_train, method=\"column\")\n",
    "# nomalize using mean and std column-wise\n",
    "dat_norm.mu.shape  # vector of means\n",
    "dat_norm.std.shape  # vector of stds\n",
    "\n",
    "x_test = dat_norm.transform(x_test)\n",
    "\n",
    "# reshape to (sample size, number channel=1, num_features)\n",
    "x_train = x_train[:, np.newaxis, :]\n",
    "x_test = x_test[:, np.newaxis, :]\n",
    "\n",
    "# train, validation, test data\n",
    "# since we have a small dataset, we just use validation data as test data\n",
    "train_data = [x_train, y_train]\n",
    "test_data = [x_test, y_test]\n",
    "\n",
    "\n",
    "##### ---- set up the user-defined model  ---- ######\n",
    "\n",
    "# x (batch_size, in_channels=1, in_width=180)\n",
    "# Conv1D (out_channels=8, kernel=10, stride=1)-> Tanh\n",
    "# pool (kernel=2)\n",
    "# Conv1D (out_channels=8, kernel=10, stride=2)-> ReLu\n",
    "# pool (kernel=2)\n",
    "# Conv1D (out_channels=4, kernel=4, stride=2) -> Sigmoid\n",
    "# pool (kernel=1)\n",
    "# Flatten1D\n",
    "# Linear (out_features=8)\n",
    "\n",
    "input_width = x_train.shape[2]  # num_features\n",
    "input_channels = 1\n",
    "num_linear_neurons = len(emotions_labels)\n",
    "out_channels = [8, 8, 4]\n",
    "kernel_sizes = [10, 10, 4]\n",
    "strides = [1, 2, 2]\n",
    "pool_kernel_sizes = [2, 2, 1]\n",
    "activations = [Tanh(), ReLU(), Sigmoid()]\n",
    "\n",
    "conv_weight_init_fn = weight_init_He_CNN\n",
    "linear_weight_init_fn = weight_init_He_CNN\n",
    "bias_init_fn = bias_init_zeros\n",
    "# criterion = SoftmaxCrossEntropy()\n",
    "criterion = CrossEntropyLoss()\n",
    "lr = 1e-2\n",
    "\n",
    "cnn1d_model = CNN1D(\n",
    "    input_width,\n",
    "    input_channels,\n",
    "    out_channels,\n",
    "    kernel_sizes,\n",
    "    strides,\n",
    "    num_linear_neurons,\n",
    "    activations,\n",
    "    conv_weight_init_fn,\n",
    "    bias_init_fn,\n",
    "    linear_weight_init_fn,\n",
    "    pool_kernel_sizes,\n",
    "    pool_mode=\"average\",\n",
    ")\n",
    "\n",
    "type(cnn1d_model)\n",
    "\n",
    "# check some utility functions\n",
    "cnn1d_model.print_structure()\n",
    "\n",
    "model_paras_list = cnn1d_model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 | Train loss: 2.0219 | Validation loss: 1.9361 \n",
      "Epoch: 001/100 | Train error: 0.8047 | Validation error: 0.7431 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 002/100 | Train loss: 1.9308 | Validation loss: 1.8792 \n",
      "Epoch: 002/100 | Train error: 0.7674 | Validation error: 0.7535 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 003/100 | Train loss: 1.8821 | Validation loss: 1.8427 \n",
      "Epoch: 003/100 | Train error: 0.7405 | Validation error: 0.7292 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 004/100 | Train loss: 1.8502 | Validation loss: 1.8251 \n",
      "Epoch: 004/100 | Train error: 0.7240 | Validation error: 0.7049 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 005/100 | Train loss: 1.8215 | Validation loss: 1.8083 \n",
      "Epoch: 005/100 | Train error: 0.6979 | Validation error: 0.7257 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 006/100 | Train loss: 1.7926 | Validation loss: 1.8029 \n",
      "Epoch: 006/100 | Train error: 0.7040 | Validation error: 0.7153 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 007/100 | Train loss: 1.7714 | Validation loss: 1.7859 \n",
      "Epoch: 007/100 | Train error: 0.6832 | Validation error: 0.7049 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 008/100 | Train loss: 1.7448 | Validation loss: 1.7813 \n",
      "Epoch: 008/100 | Train error: 0.6615 | Validation error: 0.6944 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 009/100 | Train loss: 1.7251 | Validation loss: 1.7695 \n",
      "Epoch: 009/100 | Train error: 0.6406 | Validation error: 0.7014 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 010/100 | Train loss: 1.7084 | Validation loss: 1.7481 \n",
      "Epoch: 010/100 | Train error: 0.6398 | Validation error: 0.6701 \n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 011/100 | Train loss: 1.6949 | Validation loss: 1.7379 \n",
      "Epoch: 011/100 | Train error: 0.6432 | Validation error: 0.6562 \n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 012/100 | Train loss: 1.6692 | Validation loss: 1.7226 \n",
      "Epoch: 012/100 | Train error: 0.6128 | Validation error: 0.6736 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 013/100 | Train loss: 1.6454 | Validation loss: 1.7055 \n",
      "Epoch: 013/100 | Train error: 0.6016 | Validation error: 0.6562 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 014/100 | Train loss: 1.6266 | Validation loss: 1.7120 \n",
      "Epoch: 014/100 | Train error: 0.5885 | Validation error: 0.6354 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 015/100 | Train loss: 1.6138 | Validation loss: 1.6967 \n",
      "Epoch: 015/100 | Train error: 0.5859 | Validation error: 0.6354 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 016/100 | Train loss: 1.5935 | Validation loss: 1.6962 \n",
      "Epoch: 016/100 | Train error: 0.5634 | Validation error: 0.6493 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 017/100 | Train loss: 1.5824 | Validation loss: 1.6826 \n",
      "Epoch: 017/100 | Train error: 0.5738 | Validation error: 0.6562 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 018/100 | Train loss: 1.5635 | Validation loss: 1.6783 \n",
      "Epoch: 018/100 | Train error: 0.5651 | Validation error: 0.6181 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 019/100 | Train loss: 1.5458 | Validation loss: 1.6867 \n",
      "Epoch: 019/100 | Train error: 0.5616 | Validation error: 0.5972 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 020/100 | Train loss: 1.5365 | Validation loss: 1.6678 \n",
      "Epoch: 020/100 | Train error: 0.5408 | Validation error: 0.6146 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 021/100 | Train loss: 1.5170 | Validation loss: 1.6624 \n",
      "Epoch: 021/100 | Train error: 0.5330 | Validation error: 0.6111 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 022/100 | Train loss: 1.5033 | Validation loss: 1.6599 \n",
      "Epoch: 022/100 | Train error: 0.5295 | Validation error: 0.6215 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 023/100 | Train loss: 1.4985 | Validation loss: 1.6839 \n",
      "Epoch: 023/100 | Train error: 0.5365 | Validation error: 0.6354 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 024/100 | Train loss: 1.4905 | Validation loss: 1.6712 \n",
      "Epoch: 024/100 | Train error: 0.5122 | Validation error: 0.6181 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 025/100 | Train loss: 1.4865 | Validation loss: 1.6710 \n",
      "Epoch: 025/100 | Train error: 0.5295 | Validation error: 0.6354 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 026/100 | Train loss: 1.4722 | Validation loss: 1.6410 \n",
      "Epoch: 026/100 | Train error: 0.5043 | Validation error: 0.6076 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 027/100 | Train loss: 1.4493 | Validation loss: 1.6426 \n",
      "Epoch: 027/100 | Train error: 0.5017 | Validation error: 0.6146 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 028/100 | Train loss: 1.4293 | Validation loss: 1.6377 \n",
      "Epoch: 028/100 | Train error: 0.4844 | Validation error: 0.6076 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 029/100 | Train loss: 1.4215 | Validation loss: 1.6280 \n",
      "Epoch: 029/100 | Train error: 0.4922 | Validation error: 0.6007 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 030/100 | Train loss: 1.4069 | Validation loss: 1.6667 \n",
      "Epoch: 030/100 | Train error: 0.4896 | Validation error: 0.6250 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 031/100 | Train loss: 1.4170 | Validation loss: 1.6600 \n",
      "Epoch: 031/100 | Train error: 0.4766 | Validation error: 0.5972 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 032/100 | Train loss: 1.4173 | Validation loss: 1.6834 \n",
      "Epoch: 032/100 | Train error: 0.4905 | Validation error: 0.6146 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 033/100 | Train loss: 1.4118 | Validation loss: 1.6194 \n",
      "Epoch: 033/100 | Train error: 0.4800 | Validation error: 0.6076 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 034/100 | Train loss: 1.3911 | Validation loss: 1.6085 \n",
      "Epoch: 034/100 | Train error: 0.4870 | Validation error: 0.5972 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 035/100 | Train loss: 1.3664 | Validation loss: 1.6128 \n",
      "Epoch: 035/100 | Train error: 0.4653 | Validation error: 0.6285 \n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 036/100 | Train loss: 1.3720 | Validation loss: 1.6235 \n",
      "Epoch: 036/100 | Train error: 0.4809 | Validation error: 0.6076 \n",
      "Time elapsed: 1.05 min\n",
      "Epoch: 037/100 | Train loss: 1.3494 | Validation loss: 1.5931 \n",
      "Epoch: 037/100 | Train error: 0.4549 | Validation error: 0.5972 \n",
      "Time elapsed: 1.08 min\n",
      "Epoch: 038/100 | Train loss: 1.3306 | Validation loss: 1.5822 \n",
      "Epoch: 038/100 | Train error: 0.4453 | Validation error: 0.5868 \n",
      "Time elapsed: 1.09 min\n",
      "Epoch: 039/100 | Train loss: 1.3187 | Validation loss: 1.5863 \n",
      "Epoch: 039/100 | Train error: 0.4462 | Validation error: 0.5729 \n",
      "Time elapsed: 1.12 min\n",
      "Epoch: 040/100 | Train loss: 1.3053 | Validation loss: 1.5968 \n",
      "Epoch: 040/100 | Train error: 0.4392 | Validation error: 0.5972 \n",
      "Time elapsed: 1.21 min\n",
      "Epoch: 041/100 | Train loss: 1.2994 | Validation loss: 1.6047 \n",
      "Epoch: 041/100 | Train error: 0.4427 | Validation error: 0.5799 \n",
      "Time elapsed: 1.10 min\n",
      "Epoch: 042/100 | Train loss: 1.2976 | Validation loss: 1.5810 \n",
      "Epoch: 042/100 | Train error: 0.4549 | Validation error: 0.5868 \n",
      "Time elapsed: 1.19 min\n",
      "Epoch: 043/100 | Train loss: 1.2799 | Validation loss: 1.5915 \n",
      "Epoch: 043/100 | Train error: 0.4340 | Validation error: 0.5694 \n",
      "Time elapsed: 1.10 min\n",
      "Epoch: 044/100 | Train loss: 1.2681 | Validation loss: 1.5908 \n",
      "Epoch: 044/100 | Train error: 0.4323 | Validation error: 0.5868 \n",
      "Time elapsed: 1.07 min\n",
      "Epoch: 045/100 | Train loss: 1.2585 | Validation loss: 1.5895 \n",
      "Epoch: 045/100 | Train error: 0.4375 | Validation error: 0.5799 \n",
      "Time elapsed: 1.02 min\n",
      "Epoch: 046/100 | Train loss: 1.2467 | Validation loss: 1.5544 \n",
      "Epoch: 046/100 | Train error: 0.4332 | Validation error: 0.5729 \n",
      "Time elapsed: 1.18 min\n",
      "Epoch: 047/100 | Train loss: 1.2415 | Validation loss: 1.5732 \n",
      "Epoch: 047/100 | Train error: 0.4219 | Validation error: 0.5868 \n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 048/100 | Train loss: 1.2435 | Validation loss: 1.5881 \n",
      "Epoch: 048/100 | Train error: 0.4262 | Validation error: 0.5799 \n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 049/100 | Train loss: 1.2211 | Validation loss: 1.5924 \n",
      "Epoch: 049/100 | Train error: 0.4236 | Validation error: 0.5833 \n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 050/100 | Train loss: 1.2266 | Validation loss: 1.5811 \n",
      "Epoch: 050/100 | Train error: 0.4288 | Validation error: 0.5764 \n",
      "Time elapsed: 1.24 min\n",
      "Epoch: 051/100 | Train loss: 1.2186 | Validation loss: 1.5962 \n",
      "Epoch: 051/100 | Train error: 0.4210 | Validation error: 0.5799 \n",
      "Time elapsed: 1.25 min\n",
      "Epoch: 052/100 | Train loss: 1.1928 | Validation loss: 1.6007 \n",
      "Epoch: 052/100 | Train error: 0.4080 | Validation error: 0.5764 \n",
      "Time elapsed: 1.26 min\n",
      "Epoch: 053/100 | Train loss: 1.2090 | Validation loss: 1.6105 \n",
      "Epoch: 053/100 | Train error: 0.4201 | Validation error: 0.5729 \n",
      "Time elapsed: 1.26 min\n",
      "Epoch: 054/100 | Train loss: 1.2008 | Validation loss: 1.6228 \n",
      "Epoch: 054/100 | Train error: 0.4193 | Validation error: 0.5972 \n",
      "Time elapsed: 1.27 min\n",
      "Epoch: 055/100 | Train loss: 1.2006 | Validation loss: 1.6128 \n",
      "Epoch: 055/100 | Train error: 0.4158 | Validation error: 0.5729 \n",
      "Time elapsed: 1.27 min\n",
      "Epoch: 056/100 | Train loss: 1.1733 | Validation loss: 1.5950 \n",
      "Epoch: 056/100 | Train error: 0.4036 | Validation error: 0.5694 \n",
      "Time elapsed: 1.30 min\n",
      "Epoch: 057/100 | Train loss: 1.1743 | Validation loss: 1.6293 \n",
      "Epoch: 057/100 | Train error: 0.4080 | Validation error: 0.5764 \n",
      "Time elapsed: 1.23 min\n",
      "Epoch: 058/100 | Train loss: 1.1808 | Validation loss: 1.6014 \n",
      "Epoch: 058/100 | Train error: 0.4045 | Validation error: 0.5590 \n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 059/100 | Train loss: 1.1748 | Validation loss: 1.6086 \n",
      "Epoch: 059/100 | Train error: 0.4149 | Validation error: 0.5729 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 060/100 | Train loss: 1.1624 | Validation loss: 1.5895 \n",
      "Epoch: 060/100 | Train error: 0.4149 | Validation error: 0.5556 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 061/100 | Train loss: 1.1531 | Validation loss: 1.6479 \n",
      "Epoch: 061/100 | Train error: 0.4002 | Validation error: 0.5660 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 062/100 | Train loss: 1.1402 | Validation loss: 1.6110 \n",
      "Epoch: 062/100 | Train error: 0.3906 | Validation error: 0.5694 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 063/100 | Train loss: 1.1382 | Validation loss: 1.6200 \n",
      "Epoch: 063/100 | Train error: 0.3898 | Validation error: 0.5625 \n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 064/100 | Train loss: 1.1246 | Validation loss: 1.5957 \n",
      "Epoch: 064/100 | Train error: 0.3872 | Validation error: 0.5590 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 065/100 | Train loss: 1.1249 | Validation loss: 1.6343 \n",
      "Epoch: 065/100 | Train error: 0.3819 | Validation error: 0.5833 \n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 066/100 | Train loss: 1.1119 | Validation loss: 1.6163 \n",
      "Epoch: 066/100 | Train error: 0.3880 | Validation error: 0.5729 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 067/100 | Train loss: 1.1109 | Validation loss: 1.6433 \n",
      "Epoch: 067/100 | Train error: 0.3837 | Validation error: 0.5382 \n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 068/100 | Train loss: 1.1004 | Validation loss: 1.5939 \n",
      "Epoch: 068/100 | Train error: 0.3811 | Validation error: 0.5556 \n",
      "Time elapsed: 0.93 min\n",
      "Epoch: 069/100 | Train loss: 1.0978 | Validation loss: 1.6426 \n",
      "Epoch: 069/100 | Train error: 0.3767 | Validation error: 0.5556 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 070/100 | Train loss: 1.0904 | Validation loss: 1.6081 \n",
      "Epoch: 070/100 | Train error: 0.3741 | Validation error: 0.5590 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 071/100 | Train loss: 1.0836 | Validation loss: 1.6187 \n",
      "Epoch: 071/100 | Train error: 0.3785 | Validation error: 0.5660 \n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 072/100 | Train loss: 1.0735 | Validation loss: 1.6608 \n",
      "Epoch: 072/100 | Train error: 0.3767 | Validation error: 0.5625 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 073/100 | Train loss: 1.0889 | Validation loss: 1.6287 \n",
      "Epoch: 073/100 | Train error: 0.3880 | Validation error: 0.5729 \n",
      "Time elapsed: 0.95 min\n",
      "Epoch: 074/100 | Train loss: 1.0775 | Validation loss: 1.6171 \n",
      "Epoch: 074/100 | Train error: 0.3689 | Validation error: 0.5556 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 075/100 | Train loss: 1.0781 | Validation loss: 1.6528 \n",
      "Epoch: 075/100 | Train error: 0.3759 | Validation error: 0.5729 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 076/100 | Train loss: 1.0821 | Validation loss: 1.6240 \n",
      "Epoch: 076/100 | Train error: 0.3776 | Validation error: 0.5625 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 077/100 | Train loss: 1.0638 | Validation loss: 1.6611 \n",
      "Epoch: 077/100 | Train error: 0.3611 | Validation error: 0.5764 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 078/100 | Train loss: 1.0629 | Validation loss: 1.6451 \n",
      "Epoch: 078/100 | Train error: 0.3585 | Validation error: 0.5625 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 079/100 | Train loss: 1.0543 | Validation loss: 1.6420 \n",
      "Epoch: 079/100 | Train error: 0.3611 | Validation error: 0.5556 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 080/100 | Train loss: 1.0862 | Validation loss: 1.6734 \n",
      "Epoch: 080/100 | Train error: 0.3889 | Validation error: 0.5243 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 081/100 | Train loss: 1.0762 | Validation loss: 1.6442 \n",
      "Epoch: 081/100 | Train error: 0.3776 | Validation error: 0.5521 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 082/100 | Train loss: 1.0485 | Validation loss: 1.6725 \n",
      "Epoch: 082/100 | Train error: 0.3516 | Validation error: 0.5521 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 083/100 | Train loss: 1.0353 | Validation loss: 1.6437 \n",
      "Epoch: 083/100 | Train error: 0.3516 | Validation error: 0.5451 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 084/100 | Train loss: 1.0314 | Validation loss: 1.6707 \n",
      "Epoch: 084/100 | Train error: 0.3568 | Validation error: 0.5590 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 085/100 | Train loss: 1.0280 | Validation loss: 1.6908 \n",
      "Epoch: 085/100 | Train error: 0.3516 | Validation error: 0.5660 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 086/100 | Train loss: 1.0311 | Validation loss: 1.6374 \n",
      "Epoch: 086/100 | Train error: 0.3568 | Validation error: 0.5521 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 087/100 | Train loss: 1.0434 | Validation loss: 1.6885 \n",
      "Epoch: 087/100 | Train error: 0.3594 | Validation error: 0.5451 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 088/100 | Train loss: 1.0351 | Validation loss: 1.6595 \n",
      "Epoch: 088/100 | Train error: 0.3707 | Validation error: 0.5590 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 089/100 | Train loss: 1.0237 | Validation loss: 1.6840 \n",
      "Epoch: 089/100 | Train error: 0.3420 | Validation error: 0.5451 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 090/100 | Train loss: 1.0133 | Validation loss: 1.6916 \n",
      "Epoch: 090/100 | Train error: 0.3524 | Validation error: 0.5764 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 091/100 | Train loss: 1.0156 | Validation loss: 1.6687 \n",
      "Epoch: 091/100 | Train error: 0.3498 | Validation error: 0.5521 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 092/100 | Train loss: 1.0243 | Validation loss: 1.6786 \n",
      "Epoch: 092/100 | Train error: 0.3533 | Validation error: 0.5417 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 093/100 | Train loss: 1.0068 | Validation loss: 1.6738 \n",
      "Epoch: 093/100 | Train error: 0.3490 | Validation error: 0.5417 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 094/100 | Train loss: 1.0008 | Validation loss: 1.6568 \n",
      "Epoch: 094/100 | Train error: 0.3464 | Validation error: 0.5243 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 095/100 | Train loss: 0.9786 | Validation loss: 1.7392 \n",
      "Epoch: 095/100 | Train error: 0.3290 | Validation error: 0.5660 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 096/100 | Train loss: 0.9841 | Validation loss: 1.6868 \n",
      "Epoch: 096/100 | Train error: 0.3351 | Validation error: 0.5625 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 097/100 | Train loss: 0.9830 | Validation loss: 1.7301 \n",
      "Epoch: 097/100 | Train error: 0.3368 | Validation error: 0.5660 \n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 098/100 | Train loss: 0.9909 | Validation loss: 1.6684 \n",
      "Epoch: 098/100 | Train error: 0.3411 | Validation error: 0.5521 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 099/100 | Train loss: 0.9687 | Validation loss: 1.6870 \n",
      "Epoch: 099/100 | Train error: 0.3307 | Validation error: 0.5590 \n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 100/100 | Train loss: 0.9665 | Validation loss: 1.7354 \n",
      "Epoch: 100/100 | Train error: 0.3220 | Validation error: 0.5347 \n",
      "Time elapsed: 0.92 min\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "optimizer = Adam(model_paras_list, lr=lr)\n",
    "optimizers = [optimizer]\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "output = trainer_multiclass(\n",
    "    cnn1d_model,\n",
    "    optimizers,\n",
    "    criterion,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    print_all=False,\n",
    ")\n",
    "\n",
    "training_losses, training_errors, validation_losses, validation_errors = output\n",
    "\n",
    "# reference performance:\n",
    "# out_channels = [8, 8, 4]\n",
    "# kernel_sizes = [10, 10, 4]\n",
    "# strides = [1, 2, 2]\n",
    "# activations = [Tanh(), ReLU(), Sigmoid()]\n",
    "# Epoch: 100/100 | Train loss: 0.8035 | Validation loss: 2.2211\n",
    "# Epoch: 100/100 | Train error: 0.2622 | Validation error: 0.6319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  1.7354156856716285\n",
      "Testing Error:  0.5347222222222222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.7354156856716285, 0.5347222222222222)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##------ evaluating ----- ####\n",
    "# note: eight classes to classify\n",
    "\n",
    "# evaluate\n",
    "evaluator_multiclass(cnn1d_model, criterion, test_data, batch_size=128)\n",
    "# error rate 0.534, compared with MLP error rate 0.528"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
