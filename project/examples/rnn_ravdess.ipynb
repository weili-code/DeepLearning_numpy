{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of RNN on RAVDESS data (numpy implementation)\n",
    "Wei Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAVDESS Emotional speech audio\n",
    "## https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
    "## Speech audio-only files (16bit, 48kHz .wav) from the RAVDESS.\n",
    "##\n",
    "## This portion of the RAVDESS contains 1440 files: 60 trials per actor x 24 actors = 1440.\n",
    "## The RAVDESS contains 24 professional actors (12 female, 12 male),\n",
    "## vocalizing two lexically-matched statements in a neutral North American accent.\n",
    "## Speech emotions includes calm, happy, sad, angry, fearful, surprise, and disgust expressions.\n",
    "## Each expression is produced at two levels of emotional intensity (normal, strong), with an additional neutral expression.\n",
    "\n",
    "# The filename consists of a 7-part numerical identifier (e.g., 03-01-06-01-02-01-12.wav). These identifiers define the stimulus characteristics:\n",
    "\n",
    "# Filename identifiers:\n",
    "# Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "# Vocal channel (01 = speech, 02 = song).\n",
    "# Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "# Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "# Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "# Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "# Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "# Filename example: 03-01-06-01-02-01-12.wav\n",
    "\n",
    "# Emotions in the RAVDESS dataset\n",
    "# emotions = {\n",
    "#     \"01\": \"neutral\",\n",
    "#     \"02\": \"calm\",\n",
    "#     \"03\": \"happy\",\n",
    "#     \"04\": \"sad\",\n",
    "#     \"05\": \"angry\",\n",
    "#     \"06\": \"fearful\",\n",
    "#     \"07\": \"disgust\",\n",
    "#     \"08\": \"surprised\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import soundfile\n",
    "import librosa\n",
    "\n",
    "# SoundFile is not available for a conda install.\n",
    "# pip install SoundFile\n",
    "\n",
    "# If error occurs: \".../envs/py38torch/lib/libffi.7.dylib' (no such file)\"\n",
    "# try the following:\n",
    "# cd /Users/wli169/miniconda3/envs/py38torch/lib/\n",
    "# ln -s libffi.6.dylib libffi.7.dylib\n",
    "# This command creates a symbolic link named libffi.7.dylib\n",
    "# that points to the file libffi.6.dylib.\n",
    "\n",
    "sys.path\n",
    "# If running the .py script, uncomment the next line\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "# add parent directory: adds the parent directory of the module requiring it (__file__)\n",
    "# to the beginning of the module search path.\n",
    "\n",
    "# change the working directory to the parent folder\n",
    "os.chdir(\"..\")\n",
    "\n",
    "\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import get_data_utils\n",
    "from utils import data_processor\n",
    "from models.rnn_classifier import *\n",
    "from nn.modules.loss import *\n",
    "from nn.modules.activation import *\n",
    "from nn.modules.linear import *\n",
    "from nn.modules.dropout import *\n",
    "from nn.modules.initializer import *\n",
    "from optim.adam_rnn import *\n",
    "from optim.adam import *\n",
    "from evaluation.multiclass_eval import *\n",
    "\n",
    "import random\n",
    "\n",
    "random_seed = 123\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Wei Li\n",
      "\n",
      "Last updated: 2023-12-28 21:27:52\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.17\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "numpy    : 1.21.5\n",
      "torch    : 1.12.1\n",
      "soundfile: 0.12.1\n",
      "librosa  : 0.10.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -a \"Wei Li\" -u -t -d -v -p numpy,torch,soundfile,librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 310)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset of emotions under consideration\n",
    "# emotions_labels = [\"calm\", \"happy\", \"fearful\", \"disgust\"]\n",
    "emotions_labels = [\n",
    "    \"neutral\",\n",
    "    \"calm\",\n",
    "    \"happy\",\n",
    "    \"sad\",\n",
    "    \"angry\",\n",
    "    \"fearful\",\n",
    "    \"disgust\",\n",
    "    \"surprised\",\n",
    "]\n",
    "\n",
    "###############################################\n",
    "#### -----  check on one example -------- ####\n",
    "###############################################\n",
    "\n",
    "example, sr = librosa.load(\n",
    "    \"/Users/wli169/Documents/Work/datasets/RAVDESS-speech/Actor_01/03-01-01-01-01-01-01.wav\",\n",
    "    sr=48000,  # default resampling rate sr=22050\n",
    ")\n",
    "# WL: an alternative way to load is to use soundfile.SoundFile()\n",
    "# however,there is some file cannot be properly loaded,\n",
    "# e.g. /Actor_20/03-01-06-01-01-02-20.wav\n",
    "# as the duration got truncated\n",
    "\n",
    "librosa.get_duration(y=example, sr=48000)\n",
    "\n",
    "type(example), example.shape\n",
    "# np.ndarray shape: (158558,) where 48000*1*3.3 secs\n",
    "# mono (1 channel)\n",
    "\n",
    "librosa.feature.mfcc(\n",
    "    y=example, sr=48000, n_mfcc=10\n",
    ").shape  # (n_mfcc, t=num_frames)=(10, 310), default n_mfcc=10\n",
    "\n",
    "stft = librosa.stft(example)\n",
    "librosa.feature.chroma_stft(S=stft, sr=48000, n_chroma=12).shape  #  default n_chroma=12\n",
    "\n",
    "librosa.feature.melspectrogram(\n",
    "    y=example, sr=48000, n_mels=128\n",
    ").shape  # default (n_mels=128, num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 310)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft = librosa.stft(example)\n",
    "ch1=librosa.feature.chroma_stft(S=stft, sr=48000, n_chroma=12)\n",
    "\n",
    "mc1=librosa.feature.mfcc(\n",
    "    y=example, sr=48000, n_mfcc=10\n",
    ")\n",
    "\n",
    "ch1.shape, mc1.shape\n",
    "\n",
    "result = np.vstack((mc1, ch1))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "#### -----  load data -------- ####\n",
    "### We set chroma=False, mel=False\n",
    "######################################\n",
    "\n",
    "# This function extracts audio features from a sound file\n",
    "def extract_feature2(file_name, mfcc, chroma, mel):\n",
    "    # Open the sound file using 'librosa' library and read samples into variable 'X'\n",
    "    X, sample_rate = librosa.load(file_name, sr=48000, dtype=\"float32\")\n",
    "    # If chroma is true, calculate short-time Fourier transform of X\n",
    "    if chroma:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    if mfcc:\n",
    "        mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=10).T\n",
    "        # mfccs: shape (num_frames, n_mfcc)\n",
    "        result = mfccs\n",
    "    if chroma:\n",
    "        chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate, n_chroma=12).T,\n",
    "        result = np.vstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128).T,\n",
    "        result = np.vstack((result, mel))\n",
    "    # Return the resulting numpy array containing extracted features\n",
    "\n",
    "    # shape (num_frames, n_mfcc + n_crhoma + n_mel)\n",
    "    return result\n",
    "\n",
    "### We set chroma=False, mel=False\n",
    "\n",
    "example_feature = extract_feature2(\n",
    "    \"/Users/wli169/Documents/Work/datasets/RAVDESS-speech/Actor_01/03-01-01-01-01-01-01.wav\",\n",
    "    mfcc=True,\n",
    "    chroma=False,\n",
    "    mel=False,\n",
    ")\n",
    "# shape (num_frames, num_mfccs) \n",
    "example_feature.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1152, 310, 10), (288, 310, 10))\n",
      "((1152,), (288,))\n"
     ]
    }
   ],
   "source": [
    "# load np_ravdess numpy data\n",
    "x_dat, y_dat = get_data_utils.get_np_ravdess2(emotions_labels, extract_feature2, max_frames=310, chroma_T=False, mel_T=False)\n",
    "x_dat.shape, y_dat.shape\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_dat, y_dat, test_size=0.2, random_state=2023, stratify=y_dat\n",
    ")\n",
    "x_train.shape, x_test.shape\n",
    "# since we have a small dataset, we just use validation data as test data\n",
    "# stratify=y_dat: each category is roughly equally represented in training and test data\n",
    "\n",
    "# Get the shape of the training and testing datasets\n",
    "print((x_train.shape, x_test.shape))  # (num_examples, num_frames, num_features)\n",
    "print((y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1152, 310, 10), (1152, 8), (288, 310, 10), (288, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "######## ----- RNN  ----- ##########\n",
    "######################################\n",
    "\n",
    "# process data targets\n",
    "y_train = data_processor.label_to_num(y_train, emotions_labels)\n",
    "y_test = data_processor.label_to_num(y_test, emotions_labels)\n",
    "\n",
    "np.bincount(y_train), np.bincount(y_test)\n",
    "# each categori is roughly equally represented in training and test data\n",
    "\n",
    "y_train = data_processor.to_onehot(y_train.reshape(-1, 1), len(emotions_labels))\n",
    "y_test = data_processor.to_onehot(y_test.reshape(-1, 1), len(emotions_labels))\n",
    "\n",
    "# normalize data input\n",
    "dat_norm = data_processor.input_normalizer2()\n",
    "x_train = dat_norm.fit_transform(x_train, method=\"column\")\n",
    "# nomalize using mean and std column-wise\n",
    "dat_norm.mu.shape  # vector of means (1, 1, 10)\n",
    "dat_norm.std.shape  # vector of stds (1, 1, 10)\n",
    "\n",
    "x_test = dat_norm.transform(x_test)\n",
    "\n",
    "# train, validation, test data\n",
    "# since we have a small dataset, we just use validation data as test data\n",
    "train_data = [x_train, y_train]\n",
    "test_data = [x_test, y_test]\n",
    "\n",
    "# check shapes\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ---- set up the user-defined RNN model  ---- ######\n",
    "\n",
    "# example, with two rnn layers (layer0, layer1)\n",
    "#\n",
    "#                       (output :logits)\n",
    "# layer 2                    Linear\n",
    "# layer 1    RNN  --- RNN --- RNN\n",
    "# layer 0    RNN  --- RNN --- RNN\n",
    "#            time0---time1---time2\n",
    "\n",
    "# rnn input: x (np.array): The input sequences, of shape (batch_size, seq_len, input_size).\n",
    "\n",
    "input_size = x_train.shape[2]  # num_features\n",
    "output_size = len(emotions_labels)\n",
    "rnn_layers = 2 # number of rnn layers\n",
    "hidden_size = 32\n",
    "\n",
    "rnn_weight_init_fn = weight_init_He\n",
    "linear_weight_init_fn = weight_init_He\n",
    "\n",
    "# My model\n",
    "my_rnn_model = RNNClassifier(\n",
    "    input_size, hidden_size, output_size, num_layers=rnn_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "The model architecture:\n",
      "layer0:\n",
      "\tsublayer0: <nn.modules.rnn_cell.RNNCell object at 0x16954cdf0>\n",
      "layer1:\n",
      "\tsublayer0: <nn.modules.rnn_cell.RNNCell object at 0x1691ffd90>\n",
      "layer2:\n",
      "\tsublayer0: <nn.modules.linear.Linear object at 0x16954cd00>\n",
      "\n",
      "---------------------------------\n",
      "layers with learnable parameters:\n",
      "layer0 \n",
      " (0)RNNCell\n",
      "(32, 10)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32,)\n",
      "\n",
      "layer1 \n",
      " (0)RNNCell\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32,)\n",
      "\n",
      "layer2 \n",
      " (0)linear\n",
      "(8, 32)\n",
      "(8, 1)\n",
      "\n",
      "layer0 \n",
      " (0)RNNCell\n",
      "(32, 10)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32,)\n",
      "\n",
      "layer1 \n",
      " (0)RNNCell\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32,)\n",
      "\n",
      "layer2 \n",
      " (0)linear\n",
      "(8, 32)\n",
      "(8, 1)\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "type(my_rnn_model)\n",
    "\n",
    "# check some utility functions\n",
    "my_rnn_model.print_structure()\n",
    "\n",
    "model_paras_list = my_rnn_model.get_parameters()\n",
    "\n",
    "# initialize W parameters\n",
    "print(len(model_paras_list))\n",
    "\n",
    "for i in range(len(model_paras_list)-1):\n",
    "    model_paras_list[i]['W_ih'].data=rnn_weight_init_fn(model_paras_list[i]['W_ih'].data)\n",
    "    model_paras_list[i]['W_hh'].data=rnn_weight_init_fn(model_paras_list[i]['W_hh'].data)\n",
    "model_paras_list[len(model_paras_list)-1]['W'].data=linear_weight_init_fn(model_paras_list[len(model_paras_list)-1]['W'].data)\n",
    "# the last layer is a Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/200 | Train loss: 2.3488 | Validation loss: 2.1331 \n",
      "Epoch: 001/200 | Train error: 0.8759 | Validation error: 0.8472 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 002/200 | Train loss: 2.1153 | Validation loss: 2.0181 \n",
      "Epoch: 002/200 | Train error: 0.8203 | Validation error: 0.8021 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 003/200 | Train loss: 2.0317 | Validation loss: 1.9643 \n",
      "Epoch: 003/200 | Train error: 0.8056 | Validation error: 0.7674 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/200 | Train loss: 1.9835 | Validation loss: 1.9459 \n",
      "Epoch: 004/200 | Train error: 0.7700 | Validation error: 0.7535 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/200 | Train loss: 1.9464 | Validation loss: 1.9267 \n",
      "Epoch: 005/200 | Train error: 0.7457 | Validation error: 0.7569 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/200 | Train loss: 1.9148 | Validation loss: 1.9136 \n",
      "Epoch: 006/200 | Train error: 0.7448 | Validation error: 0.7431 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/200 | Train loss: 1.8891 | Validation loss: 1.8956 \n",
      "Epoch: 007/200 | Train error: 0.7405 | Validation error: 0.7326 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/200 | Train loss: 1.8650 | Validation loss: 1.8961 \n",
      "Epoch: 008/200 | Train error: 0.7283 | Validation error: 0.7326 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/200 | Train loss: 1.8478 | Validation loss: 1.8758 \n",
      "Epoch: 009/200 | Train error: 0.7248 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 010/200 | Train loss: 1.8315 | Validation loss: 1.8931 \n",
      "Epoch: 010/200 | Train error: 0.7153 | Validation error: 0.7396 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 011/200 | Train loss: 1.8160 | Validation loss: 1.8613 \n",
      "Epoch: 011/200 | Train error: 0.7075 | Validation error: 0.7569 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 012/200 | Train loss: 1.7967 | Validation loss: 1.8567 \n",
      "Epoch: 012/200 | Train error: 0.6997 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 013/200 | Train loss: 1.7775 | Validation loss: 1.8393 \n",
      "Epoch: 013/200 | Train error: 0.6970 | Validation error: 0.7431 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 014/200 | Train loss: 1.7612 | Validation loss: 1.8310 \n",
      "Epoch: 014/200 | Train error: 0.6988 | Validation error: 0.7396 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 015/200 | Train loss: 1.7483 | Validation loss: 1.8225 \n",
      "Epoch: 015/200 | Train error: 0.6962 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 016/200 | Train loss: 1.7365 | Validation loss: 1.8143 \n",
      "Epoch: 016/200 | Train error: 0.6788 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 017/200 | Train loss: 1.7290 | Validation loss: 1.8226 \n",
      "Epoch: 017/200 | Train error: 0.6667 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 018/200 | Train loss: 1.7192 | Validation loss: 1.8068 \n",
      "Epoch: 018/200 | Train error: 0.6762 | Validation error: 0.7465 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 019/200 | Train loss: 1.7151 | Validation loss: 1.8244 \n",
      "Epoch: 019/200 | Train error: 0.6753 | Validation error: 0.7326 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 020/200 | Train loss: 1.7035 | Validation loss: 1.8000 \n",
      "Epoch: 020/200 | Train error: 0.6675 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 021/200 | Train loss: 1.6978 | Validation loss: 1.7947 \n",
      "Epoch: 021/200 | Train error: 0.6684 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 022/200 | Train loss: 1.6890 | Validation loss: 1.7924 \n",
      "Epoch: 022/200 | Train error: 0.6641 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 023/200 | Train loss: 1.6786 | Validation loss: 1.7982 \n",
      "Epoch: 023/200 | Train error: 0.6667 | Validation error: 0.7431 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 024/200 | Train loss: 1.6744 | Validation loss: 1.7884 \n",
      "Epoch: 024/200 | Train error: 0.6597 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 025/200 | Train loss: 1.6712 | Validation loss: 1.7846 \n",
      "Epoch: 025/200 | Train error: 0.6641 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 026/200 | Train loss: 1.6579 | Validation loss: 1.7755 \n",
      "Epoch: 026/200 | Train error: 0.6554 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 027/200 | Train loss: 1.6532 | Validation loss: 1.7733 \n",
      "Epoch: 027/200 | Train error: 0.6450 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 028/200 | Train loss: 1.6466 | Validation loss: 1.7712 \n",
      "Epoch: 028/200 | Train error: 0.6380 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 029/200 | Train loss: 1.6418 | Validation loss: 1.7591 \n",
      "Epoch: 029/200 | Train error: 0.6484 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 030/200 | Train loss: 1.6444 | Validation loss: 1.7543 \n",
      "Epoch: 030/200 | Train error: 0.6380 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 031/200 | Train loss: 1.6365 | Validation loss: 1.7566 \n",
      "Epoch: 031/200 | Train error: 0.6406 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 032/200 | Train loss: 1.6346 | Validation loss: 1.7372 \n",
      "Epoch: 032/200 | Train error: 0.6415 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 033/200 | Train loss: 1.6287 | Validation loss: 1.7336 \n",
      "Epoch: 033/200 | Train error: 0.6372 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 034/200 | Train loss: 1.6166 | Validation loss: 1.7401 \n",
      "Epoch: 034/200 | Train error: 0.6354 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 035/200 | Train loss: 1.6149 | Validation loss: 1.7485 \n",
      "Epoch: 035/200 | Train error: 0.6259 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 036/200 | Train loss: 1.6067 | Validation loss: 1.7279 \n",
      "Epoch: 036/200 | Train error: 0.6163 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 037/200 | Train loss: 1.5999 | Validation loss: 1.7265 \n",
      "Epoch: 037/200 | Train error: 0.6259 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 038/200 | Train loss: 1.5950 | Validation loss: 1.7297 \n",
      "Epoch: 038/200 | Train error: 0.6259 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 039/200 | Train loss: 1.5918 | Validation loss: 1.7288 \n",
      "Epoch: 039/200 | Train error: 0.6267 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 040/200 | Train loss: 1.5848 | Validation loss: 1.7248 \n",
      "Epoch: 040/200 | Train error: 0.6085 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 041/200 | Train loss: 1.5811 | Validation loss: 1.7193 \n",
      "Epoch: 041/200 | Train error: 0.6163 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 042/200 | Train loss: 1.5783 | Validation loss: 1.7205 \n",
      "Epoch: 042/200 | Train error: 0.6120 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 043/200 | Train loss: 1.5702 | Validation loss: 1.7378 \n",
      "Epoch: 043/200 | Train error: 0.6076 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 044/200 | Train loss: 1.5743 | Validation loss: 1.7293 \n",
      "Epoch: 044/200 | Train error: 0.6120 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 045/200 | Train loss: 1.5783 | Validation loss: 1.7413 \n",
      "Epoch: 045/200 | Train error: 0.6181 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 046/200 | Train loss: 1.5769 | Validation loss: 1.7234 \n",
      "Epoch: 046/200 | Train error: 0.6094 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 047/200 | Train loss: 1.5636 | Validation loss: 1.7397 \n",
      "Epoch: 047/200 | Train error: 0.6155 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 048/200 | Train loss: 1.5560 | Validation loss: 1.7143 \n",
      "Epoch: 048/200 | Train error: 0.5981 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 049/200 | Train loss: 1.5505 | Validation loss: 1.7825 \n",
      "Epoch: 049/200 | Train error: 0.5981 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 050/200 | Train loss: 1.5806 | Validation loss: 1.7124 \n",
      "Epoch: 050/200 | Train error: 0.6189 | Validation error: 0.6875 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 051/200 | Train loss: 1.5464 | Validation loss: 1.7162 \n",
      "Epoch: 051/200 | Train error: 0.5833 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 052/200 | Train loss: 1.5342 | Validation loss: 1.7346 \n",
      "Epoch: 052/200 | Train error: 0.5790 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 053/200 | Train loss: 1.5295 | Validation loss: 1.7167 \n",
      "Epoch: 053/200 | Train error: 0.5920 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 054/200 | Train loss: 1.5253 | Validation loss: 1.7351 \n",
      "Epoch: 054/200 | Train error: 0.5712 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 055/200 | Train loss: 1.5181 | Validation loss: 1.7256 \n",
      "Epoch: 055/200 | Train error: 0.5851 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 056/200 | Train loss: 1.5345 | Validation loss: 1.7347 \n",
      "Epoch: 056/200 | Train error: 0.5833 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 057/200 | Train loss: 1.5244 | Validation loss: 1.7187 \n",
      "Epoch: 057/200 | Train error: 0.5764 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 058/200 | Train loss: 1.5112 | Validation loss: 1.7281 \n",
      "Epoch: 058/200 | Train error: 0.5755 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 059/200 | Train loss: 1.5015 | Validation loss: 1.7461 \n",
      "Epoch: 059/200 | Train error: 0.5712 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 060/200 | Train loss: 1.5049 | Validation loss: 1.7352 \n",
      "Epoch: 060/200 | Train error: 0.5686 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 061/200 | Train loss: 1.5036 | Validation loss: 1.7305 \n",
      "Epoch: 061/200 | Train error: 0.5625 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 062/200 | Train loss: 1.4982 | Validation loss: 1.7267 \n",
      "Epoch: 062/200 | Train error: 0.5625 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 063/200 | Train loss: 1.4992 | Validation loss: 1.7152 \n",
      "Epoch: 063/200 | Train error: 0.5660 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 064/200 | Train loss: 1.5034 | Validation loss: 1.7111 \n",
      "Epoch: 064/200 | Train error: 0.5825 | Validation error: 0.6875 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 065/200 | Train loss: 1.4994 | Validation loss: 1.7340 \n",
      "Epoch: 065/200 | Train error: 0.5851 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 066/200 | Train loss: 1.4830 | Validation loss: 1.7310 \n",
      "Epoch: 066/200 | Train error: 0.5616 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 067/200 | Train loss: 1.4764 | Validation loss: 1.7138 \n",
      "Epoch: 067/200 | Train error: 0.5495 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 068/200 | Train loss: 1.4638 | Validation loss: 1.7518 \n",
      "Epoch: 068/200 | Train error: 0.5608 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 069/200 | Train loss: 1.4640 | Validation loss: 1.7655 \n",
      "Epoch: 069/200 | Train error: 0.5425 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 070/200 | Train loss: 1.4776 | Validation loss: 1.7306 \n",
      "Epoch: 070/200 | Train error: 0.5495 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 071/200 | Train loss: 1.4766 | Validation loss: 1.7326 \n",
      "Epoch: 071/200 | Train error: 0.5469 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 072/200 | Train loss: 1.4593 | Validation loss: 1.7568 \n",
      "Epoch: 072/200 | Train error: 0.5495 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 073/200 | Train loss: 1.4626 | Validation loss: 1.8712 \n",
      "Epoch: 073/200 | Train error: 0.5495 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 074/200 | Train loss: 1.7316 | Validation loss: 1.9197 \n",
      "Epoch: 074/200 | Train error: 0.6589 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 075/200 | Train loss: 1.7073 | Validation loss: 1.8442 \n",
      "Epoch: 075/200 | Train error: 0.6528 | Validation error: 0.7326 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 076/200 | Train loss: 1.6609 | Validation loss: 1.7476 \n",
      "Epoch: 076/200 | Train error: 0.6354 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 077/200 | Train loss: 1.6020 | Validation loss: 1.7245 \n",
      "Epoch: 077/200 | Train error: 0.6354 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 078/200 | Train loss: 1.5706 | Validation loss: 1.7190 \n",
      "Epoch: 078/200 | Train error: 0.6207 | Validation error: 0.6771 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 079/200 | Train loss: 1.5510 | Validation loss: 1.7221 \n",
      "Epoch: 079/200 | Train error: 0.5868 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 080/200 | Train loss: 1.5407 | Validation loss: 1.7235 \n",
      "Epoch: 080/200 | Train error: 0.5964 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 081/200 | Train loss: 1.5282 | Validation loss: 1.7232 \n",
      "Epoch: 081/200 | Train error: 0.5790 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 082/200 | Train loss: 1.5201 | Validation loss: 1.7202 \n",
      "Epoch: 082/200 | Train error: 0.5686 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 083/200 | Train loss: 1.5118 | Validation loss: 1.7225 \n",
      "Epoch: 083/200 | Train error: 0.5747 | Validation error: 0.6910 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 084/200 | Train loss: 1.5019 | Validation loss: 1.7169 \n",
      "Epoch: 084/200 | Train error: 0.5764 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 085/200 | Train loss: 1.4942 | Validation loss: 1.7250 \n",
      "Epoch: 085/200 | Train error: 0.5660 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 086/200 | Train loss: 1.4905 | Validation loss: 1.7241 \n",
      "Epoch: 086/200 | Train error: 0.5608 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 087/200 | Train loss: 1.4854 | Validation loss: 1.7269 \n",
      "Epoch: 087/200 | Train error: 0.5538 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 088/200 | Train loss: 1.4800 | Validation loss: 1.7332 \n",
      "Epoch: 088/200 | Train error: 0.5538 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 089/200 | Train loss: 1.4730 | Validation loss: 1.7318 \n",
      "Epoch: 089/200 | Train error: 0.5608 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 090/200 | Train loss: 1.4727 | Validation loss: 1.7309 \n",
      "Epoch: 090/200 | Train error: 0.5660 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 091/200 | Train loss: 1.4612 | Validation loss: 1.7407 \n",
      "Epoch: 091/200 | Train error: 0.5521 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 092/200 | Train loss: 1.4575 | Validation loss: 1.7547 \n",
      "Epoch: 092/200 | Train error: 0.5503 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 093/200 | Train loss: 1.4627 | Validation loss: 1.7457 \n",
      "Epoch: 093/200 | Train error: 0.5495 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 094/200 | Train loss: 1.4592 | Validation loss: 1.7481 \n",
      "Epoch: 094/200 | Train error: 0.5625 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 095/200 | Train loss: 1.4479 | Validation loss: 1.7531 \n",
      "Epoch: 095/200 | Train error: 0.5495 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 096/200 | Train loss: 1.4439 | Validation loss: 1.7437 \n",
      "Epoch: 096/200 | Train error: 0.5486 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 097/200 | Train loss: 1.4369 | Validation loss: 1.7749 \n",
      "Epoch: 097/200 | Train error: 0.5425 | Validation error: 0.7361 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 098/200 | Train loss: 1.4395 | Validation loss: 1.7544 \n",
      "Epoch: 098/200 | Train error: 0.5391 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 099/200 | Train loss: 1.4342 | Validation loss: 1.7792 \n",
      "Epoch: 099/200 | Train error: 0.5373 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 100/200 | Train loss: 1.4262 | Validation loss: 1.7721 \n",
      "Epoch: 100/200 | Train error: 0.5304 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 101/200 | Train loss: 1.4267 | Validation loss: 1.7769 \n",
      "Epoch: 101/200 | Train error: 0.5321 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 102/200 | Train loss: 1.4194 | Validation loss: 1.7935 \n",
      "Epoch: 102/200 | Train error: 0.5286 | Validation error: 0.7326 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 103/200 | Train loss: 1.4200 | Validation loss: 1.7864 \n",
      "Epoch: 103/200 | Train error: 0.5330 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 104/200 | Train loss: 1.4201 | Validation loss: 1.7960 \n",
      "Epoch: 104/200 | Train error: 0.5339 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 105/200 | Train loss: 1.4231 | Validation loss: 1.7438 \n",
      "Epoch: 105/200 | Train error: 0.5252 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 106/200 | Train loss: 1.4314 | Validation loss: 1.7996 \n",
      "Epoch: 106/200 | Train error: 0.5382 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 107/200 | Train loss: 1.4276 | Validation loss: 1.7664 \n",
      "Epoch: 107/200 | Train error: 0.5382 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 108/200 | Train loss: 1.4404 | Validation loss: 1.7658 \n",
      "Epoch: 108/200 | Train error: 0.5477 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 109/200 | Train loss: 1.4153 | Validation loss: 1.7366 \n",
      "Epoch: 109/200 | Train error: 0.5260 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 110/200 | Train loss: 1.4239 | Validation loss: 1.7671 \n",
      "Epoch: 110/200 | Train error: 0.5252 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 111/200 | Train loss: 1.4088 | Validation loss: 1.7852 \n",
      "Epoch: 111/200 | Train error: 0.5286 | Validation error: 0.6910 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 112/200 | Train loss: 1.4009 | Validation loss: 1.7781 \n",
      "Epoch: 112/200 | Train error: 0.5139 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 113/200 | Train loss: 1.3943 | Validation loss: 1.7820 \n",
      "Epoch: 113/200 | Train error: 0.5069 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 114/200 | Train loss: 1.3932 | Validation loss: 1.7837 \n",
      "Epoch: 114/200 | Train error: 0.5174 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 115/200 | Train loss: 1.3864 | Validation loss: 1.7751 \n",
      "Epoch: 115/200 | Train error: 0.5130 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 116/200 | Train loss: 1.3903 | Validation loss: 1.7988 \n",
      "Epoch: 116/200 | Train error: 0.5208 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 117/200 | Train loss: 1.4180 | Validation loss: 1.7917 \n",
      "Epoch: 117/200 | Train error: 0.5495 | Validation error: 0.7326 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 118/200 | Train loss: 1.4154 | Validation loss: 1.7694 \n",
      "Epoch: 118/200 | Train error: 0.5252 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 119/200 | Train loss: 1.4095 | Validation loss: 1.7997 \n",
      "Epoch: 119/200 | Train error: 0.5252 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 120/200 | Train loss: 1.3981 | Validation loss: 1.8027 \n",
      "Epoch: 120/200 | Train error: 0.5330 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 121/200 | Train loss: 1.3879 | Validation loss: 1.7845 \n",
      "Epoch: 121/200 | Train error: 0.5286 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 122/200 | Train loss: 1.4193 | Validation loss: 1.8104 \n",
      "Epoch: 122/200 | Train error: 0.5356 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 123/200 | Train loss: 1.4038 | Validation loss: 1.7467 \n",
      "Epoch: 123/200 | Train error: 0.5286 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 124/200 | Train loss: 1.3851 | Validation loss: 1.7863 \n",
      "Epoch: 124/200 | Train error: 0.5200 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 125/200 | Train loss: 1.3694 | Validation loss: 1.8006 \n",
      "Epoch: 125/200 | Train error: 0.5156 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 126/200 | Train loss: 1.3705 | Validation loss: 1.8144 \n",
      "Epoch: 126/200 | Train error: 0.5234 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 127/200 | Train loss: 1.3646 | Validation loss: 1.8084 \n",
      "Epoch: 127/200 | Train error: 0.5122 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 128/200 | Train loss: 1.3622 | Validation loss: 1.8067 \n",
      "Epoch: 128/200 | Train error: 0.5139 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 129/200 | Train loss: 1.3526 | Validation loss: 1.8246 \n",
      "Epoch: 129/200 | Train error: 0.4991 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 130/200 | Train loss: 1.3560 | Validation loss: 1.8018 \n",
      "Epoch: 130/200 | Train error: 0.5078 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 131/200 | Train loss: 1.3662 | Validation loss: 1.8131 \n",
      "Epoch: 131/200 | Train error: 0.5078 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 132/200 | Train loss: 1.4332 | Validation loss: 1.7872 \n",
      "Epoch: 132/200 | Train error: 0.5503 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 133/200 | Train loss: 1.4026 | Validation loss: 1.7923 \n",
      "Epoch: 133/200 | Train error: 0.5391 | Validation error: 0.6806 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 134/200 | Train loss: 1.3847 | Validation loss: 1.8175 \n",
      "Epoch: 134/200 | Train error: 0.5312 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 135/200 | Train loss: 1.4006 | Validation loss: 1.8216 \n",
      "Epoch: 135/200 | Train error: 0.5226 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 136/200 | Train loss: 1.3752 | Validation loss: 1.8123 \n",
      "Epoch: 136/200 | Train error: 0.5148 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 137/200 | Train loss: 1.3582 | Validation loss: 1.8103 \n",
      "Epoch: 137/200 | Train error: 0.5043 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 138/200 | Train loss: 1.3325 | Validation loss: 1.8328 \n",
      "Epoch: 138/200 | Train error: 0.4844 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 139/200 | Train loss: 1.3286 | Validation loss: 1.8326 \n",
      "Epoch: 139/200 | Train error: 0.4939 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 140/200 | Train loss: 1.3264 | Validation loss: 1.8299 \n",
      "Epoch: 140/200 | Train error: 0.4913 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 141/200 | Train loss: 1.3180 | Validation loss: 1.8254 \n",
      "Epoch: 141/200 | Train error: 0.4766 | Validation error: 0.6806 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 142/200 | Train loss: 1.3225 | Validation loss: 1.8312 \n",
      "Epoch: 142/200 | Train error: 0.4870 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 143/200 | Train loss: 1.3348 | Validation loss: 1.8443 \n",
      "Epoch: 143/200 | Train error: 0.4896 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 144/200 | Train loss: 1.3288 | Validation loss: 1.8272 \n",
      "Epoch: 144/200 | Train error: 0.4905 | Validation error: 0.6840 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 145/200 | Train loss: 1.3201 | Validation loss: 1.8484 \n",
      "Epoch: 145/200 | Train error: 0.4948 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 146/200 | Train loss: 1.3200 | Validation loss: 1.8642 \n",
      "Epoch: 146/200 | Train error: 0.4852 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 147/200 | Train loss: 1.3310 | Validation loss: 1.8245 \n",
      "Epoch: 147/200 | Train error: 0.4878 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 148/200 | Train loss: 1.3132 | Validation loss: 1.8630 \n",
      "Epoch: 148/200 | Train error: 0.4826 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 149/200 | Train loss: 1.3388 | Validation loss: 1.8304 \n",
      "Epoch: 149/200 | Train error: 0.4887 | Validation error: 0.6910 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 150/200 | Train loss: 1.3282 | Validation loss: 1.8650 \n",
      "Epoch: 150/200 | Train error: 0.4922 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 151/200 | Train loss: 1.3118 | Validation loss: 1.8343 \n",
      "Epoch: 151/200 | Train error: 0.4826 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 152/200 | Train loss: 1.3288 | Validation loss: 1.8132 \n",
      "Epoch: 152/200 | Train error: 0.4757 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 153/200 | Train loss: 1.3122 | Validation loss: 1.8770 \n",
      "Epoch: 153/200 | Train error: 0.4809 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 154/200 | Train loss: 1.2885 | Validation loss: 1.8371 \n",
      "Epoch: 154/200 | Train error: 0.4583 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 155/200 | Train loss: 1.2863 | Validation loss: 1.8755 \n",
      "Epoch: 155/200 | Train error: 0.4661 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 156/200 | Train loss: 1.2895 | Validation loss: 1.8853 \n",
      "Epoch: 156/200 | Train error: 0.4618 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 157/200 | Train loss: 1.3136 | Validation loss: 1.8577 \n",
      "Epoch: 157/200 | Train error: 0.4826 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 158/200 | Train loss: 1.2881 | Validation loss: 1.8821 \n",
      "Epoch: 158/200 | Train error: 0.4696 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 159/200 | Train loss: 1.2886 | Validation loss: 1.8468 \n",
      "Epoch: 159/200 | Train error: 0.4661 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 160/200 | Train loss: 1.2834 | Validation loss: 1.8997 \n",
      "Epoch: 160/200 | Train error: 0.4609 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 161/200 | Train loss: 1.2689 | Validation loss: 1.9014 \n",
      "Epoch: 161/200 | Train error: 0.4601 | Validation error: 0.7257 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 162/200 | Train loss: 1.6089 | Validation loss: 1.9634 \n",
      "Epoch: 162/200 | Train error: 0.6016 | Validation error: 0.7535 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 163/200 | Train loss: 1.6269 | Validation loss: 1.8209 \n",
      "Epoch: 163/200 | Train error: 0.6250 | Validation error: 0.6910 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 164/200 | Train loss: 1.5247 | Validation loss: 1.8034 \n",
      "Epoch: 164/200 | Train error: 0.5833 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 165/200 | Train loss: 1.4897 | Validation loss: 1.8106 \n",
      "Epoch: 165/200 | Train error: 0.5799 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 166/200 | Train loss: 1.4523 | Validation loss: 1.8088 \n",
      "Epoch: 166/200 | Train error: 0.5590 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 167/200 | Train loss: 1.4235 | Validation loss: 1.8155 \n",
      "Epoch: 167/200 | Train error: 0.5495 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 168/200 | Train loss: 1.4049 | Validation loss: 1.8095 \n",
      "Epoch: 168/200 | Train error: 0.5312 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 169/200 | Train loss: 1.3885 | Validation loss: 1.8125 \n",
      "Epoch: 169/200 | Train error: 0.5234 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 170/200 | Train loss: 1.3728 | Validation loss: 1.8121 \n",
      "Epoch: 170/200 | Train error: 0.5174 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 171/200 | Train loss: 1.3700 | Validation loss: 1.8171 \n",
      "Epoch: 171/200 | Train error: 0.5200 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 172/200 | Train loss: 1.3554 | Validation loss: 1.8133 \n",
      "Epoch: 172/200 | Train error: 0.5182 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 173/200 | Train loss: 1.3507 | Validation loss: 1.8230 \n",
      "Epoch: 173/200 | Train error: 0.5139 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 174/200 | Train loss: 1.3450 | Validation loss: 1.8266 \n",
      "Epoch: 174/200 | Train error: 0.5113 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 175/200 | Train loss: 1.3398 | Validation loss: 1.8318 \n",
      "Epoch: 175/200 | Train error: 0.5069 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 176/200 | Train loss: 1.3381 | Validation loss: 1.8352 \n",
      "Epoch: 176/200 | Train error: 0.4991 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 177/200 | Train loss: 1.3258 | Validation loss: 1.8342 \n",
      "Epoch: 177/200 | Train error: 0.4965 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 178/200 | Train loss: 1.3144 | Validation loss: 1.8514 \n",
      "Epoch: 178/200 | Train error: 0.4896 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 179/200 | Train loss: 1.3109 | Validation loss: 1.8393 \n",
      "Epoch: 179/200 | Train error: 0.4913 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 180/200 | Train loss: 1.2992 | Validation loss: 1.8640 \n",
      "Epoch: 180/200 | Train error: 0.4809 | Validation error: 0.6979 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 181/200 | Train loss: 1.2957 | Validation loss: 1.8646 \n",
      "Epoch: 181/200 | Train error: 0.4783 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 182/200 | Train loss: 1.2901 | Validation loss: 1.8691 \n",
      "Epoch: 182/200 | Train error: 0.4809 | Validation error: 0.7292 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 183/200 | Train loss: 1.2837 | Validation loss: 1.8733 \n",
      "Epoch: 183/200 | Train error: 0.4705 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 184/200 | Train loss: 1.2863 | Validation loss: 1.8546 \n",
      "Epoch: 184/200 | Train error: 0.4757 | Validation error: 0.6944 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 185/200 | Train loss: 1.2754 | Validation loss: 1.8759 \n",
      "Epoch: 185/200 | Train error: 0.4757 | Validation error: 0.6806 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 186/200 | Train loss: 1.3203 | Validation loss: 1.8851 \n",
      "Epoch: 186/200 | Train error: 0.4931 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 187/200 | Train loss: 1.3056 | Validation loss: 1.8962 \n",
      "Epoch: 187/200 | Train error: 0.4878 | Validation error: 0.7188 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 188/200 | Train loss: 1.2916 | Validation loss: 1.8932 \n",
      "Epoch: 188/200 | Train error: 0.4887 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 189/200 | Train loss: 1.2773 | Validation loss: 1.9098 \n",
      "Epoch: 189/200 | Train error: 0.4731 | Validation error: 0.7049 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 190/200 | Train loss: 1.2765 | Validation loss: 1.8895 \n",
      "Epoch: 190/200 | Train error: 0.4748 | Validation error: 0.7222 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 191/200 | Train loss: 1.2712 | Validation loss: 1.8754 \n",
      "Epoch: 191/200 | Train error: 0.4722 | Validation error: 0.6840 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 192/200 | Train loss: 1.2799 | Validation loss: 1.8645 \n",
      "Epoch: 192/200 | Train error: 0.4826 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 193/200 | Train loss: 1.2738 | Validation loss: 1.8596 \n",
      "Epoch: 193/200 | Train error: 0.4705 | Validation error: 0.7118 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 194/200 | Train loss: 1.2569 | Validation loss: 1.8900 \n",
      "Epoch: 194/200 | Train error: 0.4566 | Validation error: 0.7014 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 195/200 | Train loss: 1.2512 | Validation loss: 1.8500 \n",
      "Epoch: 195/200 | Train error: 0.4618 | Validation error: 0.7083 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 196/200 | Train loss: 1.2369 | Validation loss: 1.8816 \n",
      "Epoch: 196/200 | Train error: 0.4479 | Validation error: 0.6910 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 197/200 | Train loss: 1.2318 | Validation loss: 1.8851 \n",
      "Epoch: 197/200 | Train error: 0.4696 | Validation error: 0.6771 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 198/200 | Train loss: 1.2241 | Validation loss: 1.8908 \n",
      "Epoch: 198/200 | Train error: 0.4444 | Validation error: 0.7153 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 199/200 | Train loss: 1.2242 | Validation loss: 1.9096 \n",
      "Epoch: 199/200 | Train error: 0.4514 | Validation error: 0.6910 \n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 200/200 | Train loss: 1.2207 | Validation loss: 1.9006 \n",
      "Epoch: 200/200 | Train error: 0.4418 | Validation error: 0.6840 \n",
      "Time elapsed: 0.01 min\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "#### training  #####\n",
    "####################\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# criterion = CrossEntropyLoss2()\n",
    "# note that CrossEntropyLoss2() returns loss (np.ndarra) \n",
    "# (batch size, ) loss for each obs in the batch\n",
    "\n",
    "lr1 = 1e-3\n",
    "lr2 = 1e-3\n",
    "\n",
    "optimizer1 = Adam_rnn(model_paras_list[0:rnn_layers], lr=lr1)\n",
    "optimizer2 = Adam([model_paras_list[rnn_layers]], lr=lr2) # the output layer\n",
    "# [model_paras_list[4]]] is a list.\n",
    "\n",
    "optimizers = [optimizer1, optimizer2]\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "\n",
    "output = trainer_multiclass(\n",
    "    my_rnn_model,\n",
    "    optimizers,\n",
    "    criterion,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    print_all=False,\n",
    ")\n",
    "\n",
    "training_losses, training_errors, validation_losses, validation_errors = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  1.8741259876555771\n",
      "Testing Error:  0.6840277777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.8741259876555771, 0.6840277777777778)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##------ evaluating ----- ####\n",
    "# note: eight classes to classify\n",
    "\n",
    "# evaluate\n",
    "evaluator_multiclass(my_rnn_model, criterion, test_data, batch_size=256)\n",
    "# error rate 0.684, not impressive, yet demontrating the numpy implementation \n",
    "# of simple RNN module works as intended (check the counterpart performance using Pytorch modules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
